{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnJUALElET8I"
   },
   "source": [
    "# Exercise 1: Linear Image Classifier\n",
    "\n",
    "In this exercise you will implement a linear image classifier while getting familiar with `numpy` and the benefits of vectorized operations in Python. This exercise has 2 parts:\n",
    "\n",
    "1. Implementing loss functions, calculating gradients and implementing gradient descent.\n",
    "2. Training and evaluating several classifiers.\n",
    "\n",
    "## Submission guidelines:\n",
    "\n",
    "Your submission should only include this jupyter notebook named HW1_ID.ipynb.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "2. Write **efficient vectorized** code whenever instructed. \n",
    "3. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "4. Do not change the functions we provided you. \n",
    "4. Write your functions in the instructed python modules only. All the logic you write is imported and used using this jupyter notebook. You are allowed to add functions as long as they are located in the python modules and are imported properly.\n",
    "5. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. Any other imports are forbidden.\n",
    "6. Your code must run without errors.\n",
    "7. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support).\n",
    "8. **TIP: When there is a TODO before a missing code segment (or function), you can continue without implementing it right away; you will be referred to the missing segment later in the exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r1L4UklET8K"
   },
   "source": [
    "Q: What files do we need to upload to moodle?\n",
    "\n",
    "A: You should fill in the missing parts in this Jupyter notebook and then submit it via moodle (without any additional files).\n",
    "\n",
    "Q: How do I make sure everything works before I submit?\n",
    "\n",
    "A: You should restart your kernel and rerun all cells. Make sure you get the desired output and that you meet exercise requirements. **This is an important step. You should include your desired outputs in the output cells to make your code easier to understand.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV9XOToVGvLZ"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:00.158255Z",
     "start_time": "2022-10-29T15:20:59.290618Z"
    },
    "id": "iLXvPpILET8K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "from random import randrange\n",
    "from functools import partial\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# specify the way plots behave in jupyter notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 3.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "BtYsC3I7ET8L"
   },
   "source": [
    "# Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "-WovI1B4Gxwp"
   },
   "source": [
    "## Data download and processing Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:00.767100Z",
     "start_time": "2022-10-29T15:21:00.754066Z"
    },
    "code_folding": [],
    "hidden": true,
    "id": "sC6iBqvmGYsn"
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract(url, download_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the data if it doesn't already exist.\n",
    "    Assumes the url is a tar-ball file.\n",
    "    :param url:\n",
    "        Internet URL for the tar-file to download.\n",
    "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    :param download_dir:\n",
    "        Directory where the downloaded file is saved.\n",
    "        Example: \"data/CIFAR-10/\"\n",
    "    :return:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filename for saving the file downloaded from the internet.\n",
    "    # Use the filename from the URL and add it to the download_dir.\n",
    "    filename = url.split('/')[-1]\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Check if the file already exists.\n",
    "    # If it exists then we assume it has also been extracted,\n",
    "    # otherwise we need to download and extract it now.\n",
    "    if not os.path.exists(file_path):\n",
    "        # Check if the download directory exists, otherwise create it.\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "\n",
    "        # Download the file from the internet.\n",
    "        print(\"Downloading, This might take several minutes.\")\n",
    "        last_update_time = time.time()\n",
    "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                  filename=file_path)\n",
    "\n",
    "        print()\n",
    "        print(\"Download finished. Extracting files.\")\n",
    "\n",
    "        if file_path.endswith(\".zip\"):\n",
    "            # Unpack the zip-file.\n",
    "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
    "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "            # Unpack the tar-ball.\n",
    "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
    "\n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
    "        print(\"If not, delete the dataset folder and try again.\")\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    ''' load single batch of cifar '''\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding = 'latin1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load(ROOT):\n",
    "    ''' load all of cifar '''\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1, 6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "0qfmwr8lG3S8"
   },
   "source": [
    "## Data Download\n",
    "\n",
    "The next cell will download and extract CIFAR-10 into `datasets/cifar10/`. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset is divided into five training batches and one test batch, each with 10,000 images. The test batch contains exactly 1,000 randomly-selected images from each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:01.686261Z",
     "start_time": "2022-10-29T15:21:01.675796Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "eBbBnxJpET8L",
    "outputId": "19b0cf20-9282-492c-cad8-8d959975a10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n",
      "If not, delete the dataset folder and try again.\n"
     ]
    }
   ],
   "source": [
    "# this cell will download the data if it does not exists\n",
    "URL = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "PATH = 'datasets/cifar10/' # the script will create required directories\n",
    "maybe_download_and_extract(URL, PATH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "AIyo61vC-Dmv"
   },
   "source": [
    "## Data Preprocessing Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ersTr2wB-RAd"
   },
   "source": [
    "We have included several image processing functions. Notice the following in particular: we created an additional validation dataset you need to use for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:05.097768Z",
     "start_time": "2022-10-29T15:21:03.341893Z"
    },
    "hidden": true,
    "id": "NFUWV8LnET8M"
   },
   "outputs": [],
   "source": [
    "CIFAR10_PATH = os.path.join(PATH, 'cifar-10-batches-py')\n",
    "X_train, y_train, X_test, y_test = load(CIFAR10_PATH) # load the entire data\n",
    "\n",
    "# taking only two classes from the dataset\n",
    "X_train = X_train[np.logical_or(y_train == 0, y_train == 1)]\n",
    "y_train = y_train[np.logical_or(y_train == 0, y_train == 1)]\n",
    "X_test = X_test[np.logical_or(y_test == 0, y_test == 1)]\n",
    "y_test = y_test[np.logical_or(y_test == 0, y_test == 1)]\n",
    "\n",
    "# define a splitting for the data\n",
    "num_training = 10000\n",
    "num_validation = 1000\n",
    "num_testing = 1000\n",
    "\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "# portion from the test dataset a validation dataset for hyperparameter optimization\n",
    "mask = range(num_validation)\n",
    "X_val = X_test[mask]\n",
    "y_val = y_test[mask]\n",
    "# test dataset, without overlap with train/validation\n",
    "mask = range(num_validation, num_validation+num_testing)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# float64\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_val = X_val.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "classes = ('plane', 'car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:05.911006Z",
     "start_time": "2022-10-29T15:21:05.755837Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "hidden": true,
    "id": "Daycmt2x5cVS",
    "outputId": "fe9e8a0d-66eb-4fa3-9196-462a2da8c180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    plane\t    plane\t    plane\t    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(X, y, n=1000):\n",
    "    rand_items = np.random.randint(0, X.shape[0], size=n)\n",
    "    images = X[rand_items]\n",
    "    labels = y[rand_items]\n",
    "    return images, labels\n",
    "\n",
    "def make_random_grid(x, y, n=4, convert_to_image=True, random_flag=True):\n",
    "    if random_flag:\n",
    "        rand_items = np.random.randint(0, x.shape[0], size=n)\n",
    "    else:\n",
    "        rand_items = np.arange(0, x.shape[0])\n",
    "    images = x[rand_items]\n",
    "    labels = y[rand_items]\n",
    "    if convert_to_image:\n",
    "        grid = np.hstack(np.array([np.asarray((vec_2_img(i) + mean_image), dtype=np.int64) for i in images]))\n",
    "    else:\n",
    "        grid = np.hstack(np.array([np.asarray(i, dtype=np.int64) for i in images]))\n",
    "    print('\\t'.join('%9s' % classes[labels[j]] for j in range(n)))\n",
    "    return grid\n",
    "\n",
    "def vec_2_img(x):\n",
    "    x = np.reshape(x[:-1], (32, 32, 3))\n",
    "    return x\n",
    "\n",
    "X_batch, y_batch = get_batch(X_test, y_test, 100)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch, n=4, convert_to_image=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "RhismcUO9-xk"
   },
   "source": [
    "## Data Preprocessing Part 2\n",
    "\n",
    "We have included several image processing functions. Notice the following in particular: We subtracted the mean from all the images in order to ignore illumination conditions while keeping the content of the image. Next, we flattened the images from a tensor of shape (32x32x3) to a vector with 3072 features (pixel values) so we would be able to use a simple matrix multiplication. Finally, we concatenated each image vector with an additional feature to account for the bias. This is known as the bias trick. \n",
    "\n",
    "Make sure you understand this image processing pipeline before diving into the rest of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:06.836277Z",
     "start_time": "2022-10-29T15:21:06.555473Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "C9YCYi5KZhXD",
    "outputId": "d0d032ee-5e2d-498f-b907-3ecc1fd895ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set: (10000, 3073)\n",
      "Shape of Validation Set: (1000, 3073)\n",
      "Shape of Test Set: (1000, 3073)\n"
     ]
    }
   ],
   "source": [
    "# Final data preprocessing\n",
    "# subtract the mean from all the images in the batch\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "\n",
    "# flatten all the images in the batch (make sure you understand why this is needed)\n",
    "X_train = np.reshape(X_train, newshape=(X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, newshape=(X_val.shape[0], -1)) \n",
    "X_test = np.reshape(X_test, newshape=(X_test.shape[0], -1)) \n",
    "\n",
    "# add a bias term to all images in the batch\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]) \n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]) \n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]) \n",
    "\n",
    "print(f\"Shape of Training Set: {X_train.shape}\")\n",
    "print(f\"Shape of Validation Set: {X_val.shape}\")\n",
    "print(f\"Shape of Test Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BX0bVW0ET8N"
   },
   "source": [
    "# Linear classifier: mapping images to scores\n",
    "\n",
    "During this exercise, we will maintain a python class with basic functionality (such as training the model). the linear classifiers we will build (perceptron, logistic regression) will inherit some functionality from that class and will change several functions (such as the loss function, for example). Read the code in the next cell and make sure you understand it. You might also find this [short classes in python tutorial](https://www.hackerearth.com/practice/python/object-oriented-programming/classes-and-objects-i/tutorial/) useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:15.523094Z",
     "start_time": "2022-10-29T15:21:15.502785Z"
    },
    "id": "FXAVk7l6LVty"
   },
   "outputs": [],
   "source": [
    "class LinearClassifier(object):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Class constructor. Use this method to initiate the parameters of\n",
    "        your model (W)\n",
    "        *** Subclasses will override this. ***\n",
    "\n",
    "        Inputs:\n",
    "        - X: array of data - a 2D array of size (num_instances=N, num_features)\n",
    "        - y: 1-dimensional array of length N with binary labels\n",
    "\n",
    "        This function has no return value\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the weight of the classifier to predict a label. \n",
    "        *** Subclasses will override this. ***\n",
    "\n",
    "        Input: 2D array of size (num_instances, num_features).\n",
    "        Output: 1D array of class predictions (num_instances, 1). \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def calc_accuracy(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy on a dataset as the percentage of instances \n",
    "        that are classified correctly. \n",
    "\n",
    "        Inputs:\n",
    "        - W: array of weights\n",
    "        - X: array of data\n",
    "        - y: 1-dimensional array of length N with binary labels\n",
    "        Returns:\n",
    "        - accuracy as a single float\n",
    "        \"\"\"\n",
    "\n",
    "        accuracy = 0.0\n",
    "        ###########################################################################\n",
    "        # TODO: Implement this method.                                            #\n",
    "        ###########################################################################\n",
    "        #                          START OF YOUR CODE                             #\n",
    "        ###########################################################################\n",
    "\n",
    "        # Predict the labels of the dataset X\n",
    "        y_pred = self.predict(X=X)\n",
    "        \n",
    "        # Calculate the number of correct predictions\n",
    "        correct_predictions = np.sum(y_pred == y)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = correct_predictions / y.shape[0]\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, num_iters=100, batch_size=200, verbose=False):\n",
    "        #########################################################################\n",
    "        # TODO:                                                                 #\n",
    "        # Sample batch_size elements from the training data and their           #\n",
    "        # corresponding labels to use in every iteration.                       #\n",
    "        # Store the data in X_batch and their corresponding labels in           #\n",
    "        # y_batch                                                               #\n",
    "        #                                                                       #\n",
    "        # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
    "        # replacement is faster than sampling without replacement.              #\n",
    "        #                                                                       #\n",
    "        # Next, calculate the loss and gradient and update the weights using    #\n",
    "        # the learning rate. Use the loss_history array to save the loss on     #\n",
    "        # iteration to visualize the loss.                                      #\n",
    "        #########################################################################\n",
    "        num_instances = X.shape[0]\n",
    "        loss_history = []\n",
    "        loss = 0.0\n",
    "        for i in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "            ###########################################################################\n",
    "            # Create X_batch and y_batch. Call the loss method to get the loss value  # \n",
    "            # and grad (the loss function is being override, see the loss             #\n",
    "            # function return values).                                                #\n",
    "            # Finally, append each of the loss values created in each iteration       #\n",
    "            # to loss_history.                                                        #\n",
    "            ###########################################################################\n",
    "            #                          START OF YOUR CODE                             #\n",
    "            ###########################################################################\n",
    "            \n",
    "            # sample #batch_size samples using get_batch function\n",
    "            X_batch, y_batch = get_batch(X=X, y=y, n=batch_size)\n",
    "            \n",
    "            # Calculate the loss and the derivatives of the batch according to the current weights \n",
    "            loss, dW  = self.loss(X_batch, y_batch)\n",
    "\n",
    "            # Append the loss value to loss_history\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            ###########################################################################\n",
    "            #                           END OF YOUR CODE                              #\n",
    "            ###########################################################################\n",
    "            # TODO:                                                                   #\n",
    "            # Perform parameter update                                                #\n",
    "            # Update the weights using the gradient and the learning rate.            #\n",
    "            ###########################################################################\n",
    "            #                          START OF YOUR CODE                             #                                                         #\n",
    "            ###########################################################################\n",
    "            \n",
    "            # Decrease the weights according to the gradient the learning rate\n",
    "            self.W -= learning_rate * dW\n",
    "\n",
    "            ###########################################################################\n",
    "            #                       END OF YOUR CODE                                  #\n",
    "            ###########################################################################\n",
    "\n",
    "            if verbose and i % 100 == 0:\n",
    "                print ('iteration %d / %d: loss %f' % (i, num_iters, loss))\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute the loss function and its derivative. \n",
    "        Subclasses will override this.\n",
    "        Inputs:\n",
    "        - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
    "          data points; each point has dimension D.\n",
    "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
    "        Returns: A tuple containing:\n",
    "        - loss as a single float\n",
    "        - gradient with respect to self.W; an array of the same shape as W\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9WqAhlmLMGU"
   },
   "source": [
    "## Linear perceptron\n",
    "Our first linear classifier will include a linear function that maps images to score/scores:\n",
    "\n",
    "$$\n",
    "f(x_i; W, b) = W\\cdot x_i + b\n",
    "$$\n",
    "\n",
    "In the multiclass case, W will be a matrix that maps the input into scores (score for each class) and the final prediction will be the class with the highest score.\n",
    "The binary case is a special case where you can choose to implement W as a 2 dim matrix or as a vector. The first option treats the binary problem as a multiclass problem with 2 classes, therefore, the prediction will be the class with the highest score. In case you choose to implement W as a vector (which map the input to a single score), the final prediction is done by:\n",
    "\n",
    "\n",
    "if wÂ·x+b > 0 classify the target as 1, else classify the target as 0.\n",
    "\n",
    "**Important Note** - In this exercise we focus on the binary case, and you should implement W as a vector.\n",
    "\n",
    "Your goal is to **learn** the parameters $W$ and $b$ to best classify the images according to the provided labels.\n",
    "\n",
    "Read the next code cell. The constructor of the `LinearPerceptron` class takes as input the dataset and labels in order to create appropriate parameters. Notice we are using the bias trick and only use `w` for convenience. You may initialize `w` randomly ([0,1] or [-1,1]).\n",
    "\n",
    "Since we already have a (random) model, we can start predicting classes on images. Complete the method `predict` in the `LinearPerceptron` class. **(5 Points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:38.587623Z",
     "start_time": "2022-10-29T15:21:38.576532Z"
    },
    "id": "cfLTGvYILcJw"
   },
   "outputs": [],
   "source": [
    "class LinearPerceptron(LinearClassifier):\n",
    "    # Classifier that uses Perceptron loss\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        ###########################################################################\n",
    "        # Initiate the parameters of your model.                                  #\n",
    "        # You can assume y takes values 0...K-1 where K is number of classes      #\n",
    "        ###########################################################################\n",
    "        #                          START OF YOUR CODE                             # \n",
    "        ###########################################################################\n",
    "\n",
    "        # Create a random vector of weights with values of 1 or -1. Vector's length is as num of features\n",
    "        self.W = np.random.uniform(-1, 1, size=X.shape[1])* 0.0001\n",
    "\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = None\n",
    "        ###########################################################################\n",
    "        # Implement this method.                                                  #\n",
    "        ##########################################################################\n",
    "        #                          START OF YOUR CODE                             # \n",
    "        ###########################################################################\n",
    "        \n",
    "        # Calculate the linear function\n",
    "        z = X @ self.W\n",
    "        \n",
    "        # Classify according to the score - 1 if positive, 0 otherwise \n",
    "        y_pred = (z > 0).astype(int)\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def loss(self, X_batch, y_batch):\n",
    "        # perceptron_loss_vectorized will be implemented later\n",
    "        return perceptron_loss_vectorized(self.W, X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:40.039042Z",
     "start_time": "2022-10-29T15:21:39.994118Z"
    },
    "id": "2cb3cgLeET8N"
   },
   "outputs": [],
   "source": [
    "classifier = LinearPerceptron(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:41.067042Z",
     "start_time": "2022-10-29T15:21:40.894184Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "w2Cv7adkET8N",
    "outputId": "752d16c3-3e78-4b87-e410-62be8eaf5035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    plane\t    plane\t      car\t    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch, y_batch = get_batch(X_train, y_train, 4)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch, convert_to_image=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:21:42.911853Z",
     "start_time": "2022-10-29T15:21:42.897375Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKUh3OFFET8N",
    "outputId": "2a295c68-b089-4848-e533-966c764324cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    plane       car       car       car\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print(' '.join('%9s' % classes[y_pred[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-1RXh-lET8O"
   },
   "source": [
    "## Evaluation \n",
    "\n",
    "Complete the class method `calc_accuracy`. **(5 Points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:23:38.099891Z",
     "start_time": "2022-10-29T15:23:38.029739Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiSJ5-wvET8O",
    "outputId": "2fffb0c5-551f-4ae5-e0c4-3082d1a86338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy:  0.4961\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: \", classifier.calc_accuracy(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAFp3MOYET8O"
   },
   "source": [
    "**Explain why the accuracy on the training dataset is around 50% (remember, the model is not trained yet). **(5 Points)**** \n",
    "\n",
    "**Answer**: The perceptron model is predicting according to calculated score, which is calculated by $w$, the weights, and the data $X$:\n",
    "$$ z = w^TX,\\ \\  z\\text{ is a vector of scores} $$\n",
    "Every instance is being multiplied with the weights, and the multipication is the score of the instance.\n",
    "Predicting: \n",
    "$$ if \\  z < 0: \\ y_{pred} = 0 \\\\else: \\ y_{pred} = 1$$\n",
    "Each instance is label '1' if it is positive and 0 otherwise.\n",
    "In the current model, the prediction is being done according to a random assignment to $w$ (with no further learning). $w$ is randomly assigned with values in the range [-1,1], thus it is randomly positive or negative (50% each), and the score, which is the multipication of each instance from the dataset with the weights is also randomly - negative or positive (or 0) - 50% each. Therefore the prediction is being randomly according to the random scores. If we assume that the number of cars and planes in the data is equal (or similar) - the prediction achives 50% accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuFKR-UKET8O"
   },
   "source": [
    "## Perceptron loss\n",
    "\n",
    "Your code for this section will all be written in the next cell. In this section, we write and test code outside the classes for convenience. Notice the loss method for each class is just a call for the loss function written in the next cell. Once you are finished with implementation, everything should work.\n",
    "\n",
    "First, complete the function `perceptron_loss_naive`. This function takes as input the weights, data, labels and outputs the calculated loss as a single number and the gradients with respect to W.  **(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:23:57.192000Z",
     "start_time": "2022-10-29T15:23:57.177408Z"
    },
    "id": "McEGmknNYFXC"
   },
   "outputs": [],
   "source": [
    "def perceptron_loss_naive(W, X, y):\n",
    "    \"\"\"\n",
    "    Structured perceptron loss function, naive implementation (with loops)\n",
    "    Inputs:\n",
    "    - W: array of weights\n",
    "    - X: array of data\n",
    "    - y: 1-dimensional array of length N with labels 0...K-1, for K classes\n",
    "    Returns:\n",
    "    a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    #############################################################################\n",
    "    # Compute the perceptron loss as learned in class. Start by iterating over  #\n",
    "    # over all instances and calculate the score and true score for each.       #\n",
    "    # Now, for each class determine if the prediction is correct and update the #\n",
    "    # loss over all mistakes.                                                   #\n",
    "    # Compute the gradient of the loss function and store it as dW.             #\n",
    "    # Rather that first computing the loss and then computing the derivative,   #\n",
    "    # it may be simpler to compute the derivative at the same time that the     #\n",
    "    # loss is being computed.                                                   #\n",
    "    #############################################################################\n",
    "\n",
    "\n",
    "    # mask the zero labels to -1 for the perceptron loss\n",
    "    t = np.copy(y)\n",
    "    t[t == 0] = -1\n",
    "    \n",
    "    # iterate over all the instances\n",
    "    for row_index, instance in enumerate(X):\n",
    "        \n",
    "        # z - the multipication of the weights and the feature's values of the current instance\n",
    "        z = 0\n",
    "        \n",
    "        # iterate over every feature \n",
    "        for col_index, feature_value in enumerate(instance):\n",
    "                \n",
    "            # add the multipication fo the current feature\n",
    "            z += feature_value*W[col_index]\n",
    "                      \n",
    "        # Calculate the loss for the current instance\n",
    "        cur_loss = max(0, -z*t[row_index])\n",
    "        \n",
    "        # update the total loss (if loss is 0 - the instance was predicted correct and the loss doesn't change)\n",
    "        loss += cur_loss\n",
    "        \n",
    "        # iterate over every derviative in dW and update it according to the current prediction using the gradient descent \n",
    "        for col_index in range (len(dW)):\n",
    "            \n",
    "            # compute the derivatives according to the current instance. update dW if the instance was predicted wrong            \n",
    "            dW[col_index] -= int(not z*y[row_index]<0) * t[row_index] * instance[col_index]\n",
    "        \n",
    "\n",
    "    # flatten dW to 1-d array and divide by the number of samples (instances)\n",
    "    dW = dW.flatten()\n",
    "    dW = dW / X.shape[0]\n",
    "    \n",
    "    # Divide the loss with the number of samples (instances)\n",
    "    loss = loss / X.shape[0]\n",
    "            \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:23:58.297179Z",
     "start_time": "2022-10-29T15:23:58.278906Z"
    },
    "id": "tGcQrlGJET8O"
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(3073, 1) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:23:59.483591Z",
     "start_time": "2022-10-29T15:23:59.450741Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKmH67DEET8O",
    "outputId": "fe871e58-b641-40d3-accd-7e1cd4d0dc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.169521\n",
      "CPU times: user 30.1 s, sys: 585 ms, total: 30.7 s\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_naive, _ = perceptron_loss_naive(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-Hh-R7bET8P"
   },
   "source": [
    "Once your code works, complete the function `perceptron_loss_vectorized` and compare the results of the two functions using the cell below. **(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:24:11.592697Z",
     "start_time": "2022-10-29T15:24:11.576004Z"
    },
    "id": "w1HLNSCWYIRK"
   },
   "outputs": [],
   "source": [
    "def perceptron_loss_vectorized(W, X, y):\n",
    "    \"\"\"\n",
    "    Vectorized version of perceptron_loss_naive. instead of loops, should use \n",
    "    numpy vectorization.\n",
    "\n",
    "    Inputs and outputs are the same as perceptron_loss_naive.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    #############################################################################\n",
    "    # Implement a vectorized version of the perceptron loss, storing the       #\n",
    "    # result in loss and the gradient in dW                                     #\n",
    "    #############################################################################\n",
    "\n",
    "    \n",
    "    # mask the zero labels to -1 for the perceptron loss\n",
    "    t = np.copy(y)\n",
    "    t[t == 0] = -1\n",
    "    \n",
    "    # Calcaulte z - array of scores for each instance and flatten it to 1-d vector\n",
    "    z = (X @ W).flatten()\n",
    "    \n",
    "    # Calculate the losses (Create a vector)\n",
    "    loss_vector = np.maximum(0, -z * t)\n",
    "\n",
    "    # Sum the losses\n",
    "    loss = np.sum(loss_vector)\n",
    "    \n",
    "    # Divide the loss with the number of samples (instances)\n",
    "    loss = loss / X.shape[0]\n",
    "    \n",
    "    # Calculate the dervitaives for the gradient \n",
    "    dW = - (((z * t < 0).astype(int)) * t) @ X\n",
    "\n",
    "    dW = dW / X.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:24:12.996442Z",
     "start_time": "2022-10-29T15:24:12.949777Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_puMMu8vET8P",
    "outputId": "910a25b9-0067-4c02-fb5d-5b11137458ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.169521\n",
      "CPU times: user 8.68 ms, sys: 3.13 ms, total: 11.8 ms\n",
      "Wall time: 3.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print(f'y_val:\\n{y_val}\\n')\n",
    "loss_vectorized, _ = perceptron_loss_vectorized(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6oNHXGHET8P"
   },
   "source": [
    "You might not see big changes in time due to other computing factors. In big enough datasets it would be crucial to use the vectorized version.\n",
    "\n",
    "We have obtained an efficient function for loss and gradient calculation and we can now train our network. Complete the function `train` in the `LinearClassifier` class. (**15 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:24:38.956156Z",
     "start_time": "2022-10-29T15:24:31.984850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QtvCxghET8P",
    "outputId": "1aaeba56-864b-442f-ef6c-a3e0e9fe7c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 0.110678\n",
      "iteration 100 / 1500: loss 0.012794\n",
      "iteration 200 / 1500: loss 0.015634\n",
      "iteration 300 / 1500: loss 0.013098\n",
      "iteration 400 / 1500: loss 0.009219\n",
      "iteration 500 / 1500: loss 0.012550\n",
      "iteration 600 / 1500: loss 0.007560\n",
      "iteration 700 / 1500: loss 0.009509\n",
      "iteration 800 / 1500: loss 0.008345\n",
      "iteration 900 / 1500: loss 0.011877\n",
      "iteration 1000 / 1500: loss 0.008352\n",
      "iteration 1100 / 1500: loss 0.007600\n",
      "iteration 1200 / 1500: loss 0.006773\n",
      "iteration 1300 / 1500: loss 0.003422\n",
      "iteration 1400 / 1500: loss 0.006106\n",
      "CPU times: user 5.78 s, sys: 1.71 s, total: 7.49 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perceptron = LinearPerceptron(X_train, y_train)\n",
    "loss_history = perceptron.train(X_train, y_train, learning_rate=1e-7, \n",
    "                                num_iters=1500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:24:39.656566Z",
     "start_time": "2022-10-29T15:24:39.516553Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "_jzvksCFET8P",
    "outputId": "35a93ae5-393f-43ba-ce4c-a0ade49eb1e9",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:24:40.310924Z",
     "start_time": "2022-10-29T15:24:40.267510Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFNormxyET8P",
    "outputId": "7aa6b408-7826-4d59-a99c-5f40725a0b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7966\n",
      "Testing accuracy:  0.767\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", perceptron.calc_accuracy(X_train, y_train))\n",
    "print(\"Testing accuracy: \", perceptron.calc_accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R277VSx8ET8P"
   },
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Your model should have improved from 50% accuracy to ~75% accuracy in a matter of seconds. Now, use the validation set to tune hyperparameters by training different models (using the training dataset) and evaluating the performance using the validation dataset. Save the results in a dictionary mapping tuples of the form `(learning_rate, batch_size)` to tuples of the form `(training_accuracy, validation_accuracy)`. Finally, you should evaluate the best model on the testing dataset. \n",
    "\n",
    "Use a small value for the number of iterations as you develop your code. Once you are confident that everything works, run it again for more iterations. **(5 points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:28:28.780040Z",
     "start_time": "2022-10-29T15:27:34.777137Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_g5iSBQET8Q",
    "outputId": "95953a49-5ff4-456e-db93-734fad51b975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 0.000000\n",
      "iteration 100 / 1500: loss 0.000000\n",
      "iteration 200 / 1500: loss 0.000000\n",
      "iteration 300 / 1500: loss 0.000000\n",
      "iteration 400 / 1500: loss 0.000000\n",
      "iteration 500 / 1500: loss 1.218856\n",
      "iteration 600 / 1500: loss 0.905480\n",
      "iteration 700 / 1500: loss 0.000000\n",
      "iteration 800 / 1500: loss 0.000000\n",
      "iteration 900 / 1500: loss 0.000000\n",
      "iteration 1000 / 1500: loss 0.000000\n",
      "iteration 1100 / 1500: loss 0.000000\n",
      "iteration 1200 / 1500: loss 0.000000\n",
      "iteration 1300 / 1500: loss 0.461283\n",
      "iteration 1400 / 1500: loss 2.528021\n",
      "iteration 0 / 1500: loss 0.094008\n",
      "iteration 100 / 1500: loss 0.010619\n",
      "iteration 200 / 1500: loss 0.011494\n",
      "iteration 300 / 1500: loss 0.022647\n",
      "iteration 400 / 1500: loss 0.007653\n",
      "iteration 500 / 1500: loss 0.008702\n",
      "iteration 600 / 1500: loss 0.007984\n",
      "iteration 700 / 1500: loss 0.011485\n",
      "iteration 800 / 1500: loss 0.018705\n",
      "iteration 900 / 1500: loss 0.009086\n",
      "iteration 1000 / 1500: loss 0.006291\n",
      "iteration 1100 / 1500: loss 0.011546\n",
      "iteration 1200 / 1500: loss 0.019861\n",
      "iteration 1300 / 1500: loss 0.003603\n",
      "iteration 1400 / 1500: loss 0.007197\n",
      "iteration 0 / 1500: loss 0.086603\n",
      "iteration 100 / 1500: loss 0.016972\n",
      "iteration 200 / 1500: loss 0.014860\n",
      "iteration 300 / 1500: loss 0.013270\n",
      "iteration 400 / 1500: loss 0.005871\n",
      "iteration 500 / 1500: loss 0.012683\n",
      "iteration 600 / 1500: loss 0.009539\n",
      "iteration 700 / 1500: loss 0.014340\n",
      "iteration 800 / 1500: loss 0.010791\n",
      "iteration 900 / 1500: loss 0.007797\n",
      "iteration 1000 / 1500: loss 0.009036\n",
      "iteration 1100 / 1500: loss 0.004261\n",
      "iteration 1200 / 1500: loss 0.006123\n",
      "iteration 1300 / 1500: loss 0.008145\n",
      "iteration 1400 / 1500: loss 0.005942\n",
      "iteration 0 / 1500: loss 0.076980\n",
      "iteration 100 / 1500: loss 0.014379\n",
      "iteration 200 / 1500: loss 0.010775\n",
      "iteration 300 / 1500: loss 0.011170\n",
      "iteration 400 / 1500: loss 0.007780\n",
      "iteration 500 / 1500: loss 0.008207\n",
      "iteration 600 / 1500: loss 0.009164\n",
      "iteration 700 / 1500: loss 0.006715\n",
      "iteration 800 / 1500: loss 0.006894\n",
      "iteration 900 / 1500: loss 0.009461\n",
      "iteration 1000 / 1500: loss 0.007591\n",
      "iteration 1100 / 1500: loss 0.013933\n",
      "iteration 1200 / 1500: loss 0.010250\n",
      "iteration 1300 / 1500: loss 0.010527\n",
      "iteration 1400 / 1500: loss 0.007345\n",
      "iteration 0 / 1500: loss 0.000000\n",
      "iteration 100 / 1500: loss 0.000000\n",
      "iteration 200 / 1500: loss 0.000000\n",
      "iteration 300 / 1500: loss 0.000000\n",
      "iteration 400 / 1500: loss 0.000000\n",
      "iteration 500 / 1500: loss 3.625863\n",
      "iteration 600 / 1500: loss 20.041740\n",
      "iteration 700 / 1500: loss 11.674010\n",
      "iteration 800 / 1500: loss 0.000000\n",
      "iteration 900 / 1500: loss 0.000000\n",
      "iteration 1000 / 1500: loss 0.000000\n",
      "iteration 1100 / 1500: loss 60.785734\n",
      "iteration 1200 / 1500: loss 0.000000\n",
      "iteration 1300 / 1500: loss 0.000000\n",
      "iteration 1400 / 1500: loss 29.022545\n",
      "iteration 0 / 1500: loss 0.058984\n",
      "iteration 100 / 1500: loss 0.577236\n",
      "iteration 200 / 1500: loss 0.394740\n",
      "iteration 300 / 1500: loss 0.228060\n",
      "iteration 400 / 1500: loss 0.317407\n",
      "iteration 500 / 1500: loss 0.258387\n",
      "iteration 600 / 1500: loss 0.748659\n",
      "iteration 700 / 1500: loss 0.349906\n",
      "iteration 800 / 1500: loss 0.567859\n",
      "iteration 900 / 1500: loss 0.336308\n",
      "iteration 1000 / 1500: loss 0.363932\n",
      "iteration 1100 / 1500: loss 1.132531\n",
      "iteration 1200 / 1500: loss 0.257050\n",
      "iteration 1300 / 1500: loss 0.333808\n",
      "iteration 1400 / 1500: loss 0.372818\n",
      "iteration 0 / 1500: loss 0.081359\n",
      "iteration 100 / 1500: loss 0.319352\n",
      "iteration 200 / 1500: loss 0.339296\n",
      "iteration 300 / 1500: loss 0.219595\n",
      "iteration 400 / 1500: loss 0.490254\n",
      "iteration 500 / 1500: loss 0.336796\n",
      "iteration 600 / 1500: loss 0.258391\n",
      "iteration 700 / 1500: loss 0.412573\n",
      "iteration 800 / 1500: loss 0.328362\n",
      "iteration 900 / 1500: loss 0.133991\n",
      "iteration 1000 / 1500: loss 0.304342\n",
      "iteration 1100 / 1500: loss 0.191600\n",
      "iteration 1200 / 1500: loss 0.682458\n",
      "iteration 1300 / 1500: loss 0.294040\n",
      "iteration 1400 / 1500: loss 0.399691\n",
      "iteration 0 / 1500: loss 0.034019\n",
      "iteration 100 / 1500: loss 0.231604\n",
      "iteration 200 / 1500: loss 1.034011\n",
      "iteration 300 / 1500: loss 0.177111\n",
      "iteration 400 / 1500: loss 0.256706\n",
      "iteration 500 / 1500: loss 0.312433\n",
      "iteration 600 / 1500: loss 0.327765\n",
      "iteration 700 / 1500: loss 0.196565\n",
      "iteration 800 / 1500: loss 0.179017\n",
      "iteration 900 / 1500: loss 0.262719\n",
      "iteration 1000 / 1500: loss 0.138115\n",
      "iteration 1100 / 1500: loss 0.154176\n",
      "iteration 1200 / 1500: loss 0.840851\n",
      "iteration 1300 / 1500: loss 0.182238\n",
      "iteration 1400 / 1500: loss 0.399719\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 train accuracy: 0.758100 val accuracy: 0.769000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 train accuracy: 0.783500 val accuracy: 0.788000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 train accuracy: 0.797700 val accuracy: 0.800000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 train accuracy: 0.754100 val accuracy: 0.750000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 train accuracy: 0.747100 val accuracy: 0.741000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 train accuracy: 0.811200 val accuracy: 0.802000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 train accuracy: 0.833100 val accuracy: 0.831000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 train accuracy: 0.765900 val accuracy: 0.746000\n",
      "best validation accuracy achieved during cross-validation: 0.831000\n",
      "linear perceptron on raw pixels final test set accuracy: 0.812000\n"
     ]
    }
   ],
   "source": [
    "# You are encouraged to experiment with additional values\n",
    "learning_rates = [1e-7, 5e-6]\n",
    "batch_sizes = [1, 100, 200, 500]\n",
    "\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_perceptron = None # The LinearPerceptron object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "#                            START OF YOUR CODE                                #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# iterate over every possible combinations of learning rates and batch sizes\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        # learn a model using the training model\n",
    "        perceptron = LinearPerceptron(X_train, y_train)\n",
    "        perceptron.train(X_train, y_train, learning_rate=learning_rate, \n",
    "                                        num_iters=1500, batch_size=batch_size, verbose=True)\n",
    "        \n",
    "        # calculate the accuracy of the validation set\n",
    "        val_accuracy = perceptron.calc_accuracy(X_val, y_val)\n",
    "        \n",
    "        # save the accuracies in results as tuple of accuracy accordign to the training dataset and validation dataset\n",
    "        results[(learning_rate, batch_size)] = (perceptron.calc_accuracy(X_train, y_train), val_accuracy)\n",
    "        \n",
    "        # save the best perceptron - the highest accuracy of the validation set\n",
    "        if val_accuracy > best_val:\n",
    "            \n",
    "            # update best_val and best_perceptron\n",
    "            best_val = val_accuracy\n",
    "            best_perceptron = perceptron\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, batch_size in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, batch_size)]\n",
    "    print ('lr %e batch_size %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, batch_size, train_accuracy, val_accuracy))\n",
    "    \n",
    "print ('best validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "test_accuracy = best_perceptron.calc_accuracy(X_test, y_test)\n",
    "print ('linear perceptron on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upoW3pQ1ET8Q"
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "Another choice for a binary classifier is the binary logistic regression classifier. Unlike the perceptron which treats the outputs as uncalibrated and possibly difficult to interpret scores for each class, the binary logistic regression classifier gives a slightly more intuitive output in the form of normalized class probabilities. In this classifier, the function mapping $f(x_i; W, b) = W\\cdot x_i + b$ stays unchanged but we now interpret these scores as the unnormalized log probabilities for each class and replace the perceptron loss with a cross-entropy loss. In this exercise, we will define our binary logistic regression classifier to have one input.       \n",
    "\n",
    "Read the next code cell. The constructor of the `LogisticRegression` class takes as input the dataset and labels in order to create appropriate parameters. Notice we are using the bias trick and only use the matrix `w` for convenience. Since we already have a (random) model, we can start predicting classes on images. Complete the method `predict` in the `LogisticRegression` class - remember you need to implement the sigmoid function before you can obtain predictions using your classifier. **(10 Points)**\n",
    "\n",
    "**Important note**: values passed to the `sigmoid` function can be arbitrarily large or small. When we take the exponent of such values, we might encounter extreme values that might *overflow*. This is known as numerical instability and you should always take care when you use exponent in your functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:30:35.229664Z",
     "start_time": "2022-10-29T15:30:35.184722Z"
    },
    "id": "Y9cU2sJ_X96d"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Numerically stable Sigmoid function.\n",
    "\n",
    "    Input: any unnormalized log probabilities vector\n",
    "    Output: normalized probabilities\n",
    "    \"\"\"\n",
    "    #############################################################################\n",
    "    # Implement the function                                                    #\n",
    "    #############################################################################\n",
    "\n",
    "    #  Avoid overflow by multiplying by exp(x)/exp(x)  \n",
    "    return np.exp(x) / (1 + np.exp(x))\n",
    "    \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:30:52.504993Z",
     "start_time": "2022-10-29T15:30:52.486057Z"
    },
    "id": "oGClf3GJLlBp"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(LinearClassifier):\n",
    "    # Classifer that uses sigmoid and binary cross entropy loss\n",
    "    def __init__(self, X, y):\n",
    "        self.W = None\n",
    "        ###########################################################################\n",
    "        # Initiate the parameters of your model.                                  #\n",
    "        ###########################################################################\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Create a random vector of weights with values of 1 or -1. Vector's length is as num of features\n",
    "        self.W = np.random.uniform(-1, 1, size=X.shape[1])* 0.0001\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = None\n",
    "        ###########################################################################\n",
    "        # Implement this method.                                                  #\n",
    "        ###########################################################################\n",
    "        \n",
    "        # Calculate the scores\n",
    "        z = X @ self.W\n",
    "        \n",
    "        # Calculate probabilities using the sigmoid activation function\n",
    "        y_pred = sigmoid(z)        \n",
    "        \n",
    "        # Classify according to the probabilities\n",
    "        y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "\n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def loss(self, X_batch, y_batch):\n",
    "        # will be implemented later\n",
    "        return binary_cross_entropy(self.W, X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:30:53.132207Z",
     "start_time": "2022-10-29T15:30:53.121237Z"
    },
    "id": "BRrb-mb5ET8Q"
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:30:53.866044Z",
     "start_time": "2022-10-29T15:30:53.729569Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "id": "jUb2tkIMET8Q",
    "outputId": "291f15f3-2027-4203-e341-932763106cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    plane\t      car\t    plane\t    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch, y_batch = get_batch(X_train, y_train, 4)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:31:05.584563Z",
     "start_time": "2022-10-29T15:31:05.559650Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I5T0LiBET8Q",
    "outputId": "c2163b3f-210c-4960-9800-4ab2d54fd9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        plane         plane           car         plane\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print(' '.join('%13s' % classes[y_pred[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:31:10.105426Z",
     "start_time": "2022-10-29T15:31:10.033927Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29GDDyzIET8Q",
    "outputId": "22eea029-a2b6-441d-dee6-b1819eda9b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy:  0.6586\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: \", logistic.calc_accuracy(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vpy2WTyGET8Q"
   },
   "source": [
    "## Binary cross-entropy\n",
    "\n",
    "Your code for this section will written in the next cell. \n",
    "\n",
    "Complete the function `binary_cross_entropy` using vectorized code. This function takes as input the weights, data, labels and outputs the calculated loss as a single number and the gradients with respect to W. (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:31:30.874716Z",
     "start_time": "2022-10-29T15:31:30.826315Z"
    },
    "id": "pfjEDW6n3mRu"
   },
   "outputs": [],
   "source": [
    "def binary_cross_entropy(W, X, y):\n",
    "    \"\"\"\n",
    "    Structured BCE loss function. Implement this function using vectorized code.\n",
    "    Inputs:\n",
    "    - W: array of weights\n",
    "    - X: array of data\n",
    "    - y: 1-dimensional array of length N with binary labels (0,1). \n",
    "    Returns:\n",
    "    a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    #############################################################################\n",
    "    # Implement the function and store result in loss and the gradint in dW     #\n",
    "    # Note: in class you defined BCE that takes values from the range (-1,1).   #\n",
    "    # and the sigmoid function generally outputs values in the range (0,1).     #\n",
    "    # Make the proper adjustments for your code to work.                        #\n",
    "    #############################################################################\n",
    "\n",
    "    # mask the zero labels to -1 for the perceptron loss\n",
    "    t = np.copy(y)\n",
    "    t[t == 0] = -1\n",
    "    \n",
    "    # Calcaulte z - array of scores for each instance and flatten it to 1-d vector\n",
    "    z = (X @ W).flatten()\n",
    "    \n",
    "    # Calculate the losses (Create a vector)\n",
    "    loss_vector = -np.log(sigmoid(t*z))\n",
    "    \n",
    "    # Sum the losses\n",
    "    loss = np.sum(loss_vector)\n",
    "    \n",
    "    # Divide the loss with the number of samples (instances)\n",
    "    loss = loss / X.shape[0]\n",
    "\n",
    "    # Calculate the dervitaives for the gradient \n",
    "    dW = - sigmoid(-t*z)*t @ X\n",
    "    \n",
    "    # Reshape according to W\n",
    "    dW = (dW / X.shape[0]).reshape(W.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:31:34.082144Z",
     "start_time": "2022-10-29T15:31:34.066172Z"
    },
    "id": "EvLw8x4oET8Q"
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(3073, 1) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:31:36.963381Z",
     "start_time": "2022-10-29T15:31:36.923469Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VKKB4y8ET8Q",
    "outputId": "69441e31-0264-4ef0-bd70-dfbaf258da76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.662647\n",
      "CPU times: user 10 ms, sys: 3.65 ms, total: 13.7 ms\n",
      "Wall time: 2.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_naive, grad_naive = binary_cross_entropy(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss_naive, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IawKSQqf8vSq"
   },
   "source": [
    "You are provided with a gradient test in the next cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:32:14.847516Z",
     "start_time": "2022-10-29T15:32:14.835995Z"
    },
    "id": "nms4Rd7O8s2l"
   },
   "outputs": [],
   "source": [
    "def grad_check(f, x, analytic_grad, num_checks=10, h=1e-5):\n",
    "    for i in range(num_checks):\n",
    "        ix = tuple([randrange(m) for m in x.shape])\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evaluate f(x + h)\n",
    "        x[ix] = oldval - h # increment by h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # reset\n",
    "\n",
    "        grad_numerical = (fxph - fxmh) / (2 * h)\n",
    "        grad_analytic = analytic_grad[ix]\n",
    "        rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
    "        print ('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:32:16.311794Z",
     "start_time": "2022-10-29T15:32:16.096941Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0OWqVCzET8R",
    "outputId": "208134b9-db41-46bf-b8ee-73077bb65d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 4.922398 analytic: 4.922398, relative error: 1.317785e-08\n",
      "numerical: 10.299495 analytic: 10.299495, relative error: 1.436914e-08\n",
      "numerical: -2.101280 analytic: -2.101280, relative error: 2.668473e-08\n",
      "numerical: 9.140090 analytic: 9.140090, relative error: 1.572259e-08\n",
      "numerical: 6.679236 analytic: 6.679236, relative error: 1.362782e-08\n",
      "numerical: 8.124965 analytic: 8.124965, relative error: 1.259012e-08\n",
      "numerical: 0.384687 analytic: 0.384686, relative error: 2.360454e-07\n",
      "numerical: 7.662882 analytic: 7.662882, relative error: 2.019690e-08\n",
      "numerical: 4.629897 analytic: 4.629897, relative error: 8.144425e-09\n",
      "numerical: 12.802472 analytic: 12.802471, relative error: 7.503970e-09\n"
     ]
    }
   ],
   "source": [
    "loss, grad = binary_cross_entropy(W, X_val, y_val)\n",
    "f = lambda w: binary_cross_entropy(w, X_val, y_val)[0]\n",
    "grad_numerical = grad_check(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-qL6Ti_ET8R"
   },
   "source": [
    "If implemented correctly, the training procedure you already implemented should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:32:33.879334Z",
     "start_time": "2022-10-29T15:32:29.754892Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlW4q5xjET8R",
    "outputId": "4e639294-486c-40b8-cad1-8f49116b0509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 0.680375\n",
      "iteration 100 / 1500: loss 0.460728\n",
      "iteration 200 / 1500: loss 0.433085\n",
      "iteration 300 / 1500: loss 0.531573\n",
      "iteration 400 / 1500: loss 0.493740\n",
      "iteration 500 / 1500: loss 0.390176\n",
      "iteration 600 / 1500: loss 0.473789\n",
      "iteration 700 / 1500: loss 0.426282\n",
      "iteration 800 / 1500: loss 0.505600\n",
      "iteration 900 / 1500: loss 0.346889\n",
      "iteration 1000 / 1500: loss 0.452802\n",
      "iteration 1100 / 1500: loss 0.419014\n",
      "iteration 1200 / 1500: loss 0.389751\n",
      "iteration 1300 / 1500: loss 0.415639\n",
      "iteration 1400 / 1500: loss 0.410263\n",
      "CPU times: user 5.66 s, sys: 1.77 s, total: 7.43 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logistic = LogisticRegression(X_train, y_train)\n",
    "loss_history = logistic.train(X_train, y_train, \n",
    "                         learning_rate=1e-7,\n",
    "                         num_iters=1500,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:32:34.608148Z",
     "start_time": "2022-10-29T15:32:34.441343Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "v_6Pf6lYET8R",
    "outputId": "f7d461cd-8211-4eeb-fe63-ae5e75ee18f2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:32:35.262213Z",
     "start_time": "2022-10-29T15:32:35.201690Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4S2RkwT3ET8R",
    "outputId": "d1e1232a-da7b-4b80-a7e4-18a21923d94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8156\n",
      "Testing accuracy:  0.819\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", logistic.calc_accuracy(X_train, y_train))\n",
    "print(\"Testing accuracy: \", logistic.calc_accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-1hg3RWET8R"
   },
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Your model should have improved from 50% accuracy to ~75% accuracy in a matter of seconds. Now, use the validation set to tune hyperparameters by training different models (using the training dataset) and evaluating the performance using the validation dataset. Save the results in a dictionary mapping tuples of the form `(learning_rate, batch_size)` to tuples of the form `(training_accuracy, validation_accuracy)`. Finally, you should evaluate the best model on the testing dataset. \n",
    "\n",
    "Use a small value for the number of iterations as you develop your code. Once you are confident that everything works, run it again for more iterations. **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T15:34:05.819661Z",
     "start_time": "2022-10-29T15:33:33.339414Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxXvTbhJET8R",
    "outputId": "6acf3087-3461-4715-92c9-0fc4029f6c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 0.708428\n",
      "iteration 100 / 1500: loss 0.435071\n",
      "iteration 200 / 1500: loss 0.461190\n",
      "iteration 300 / 1500: loss 0.168080\n",
      "iteration 400 / 1500: loss 0.491432\n",
      "iteration 500 / 1500: loss 0.207078\n",
      "iteration 600 / 1500: loss 0.059317\n",
      "iteration 700 / 1500: loss 0.034929\n",
      "iteration 800 / 1500: loss 0.044725\n",
      "iteration 900 / 1500: loss 1.436801\n",
      "iteration 1000 / 1500: loss 0.116542\n",
      "iteration 1100 / 1500: loss 0.396460\n",
      "iteration 1200 / 1500: loss 0.011636\n",
      "iteration 1300 / 1500: loss 0.911647\n",
      "iteration 1400 / 1500: loss 0.605586\n",
      "iteration 0 / 1500: loss 0.667557\n",
      "iteration 100 / 1500: loss 0.453677\n",
      "iteration 200 / 1500: loss 0.427122\n",
      "iteration 300 / 1500: loss 0.496414\n",
      "iteration 400 / 1500: loss 0.517709\n",
      "iteration 500 / 1500: loss 0.408375\n",
      "iteration 600 / 1500: loss 0.407171\n",
      "iteration 700 / 1500: loss 0.493231\n",
      "iteration 800 / 1500: loss 0.390096\n",
      "iteration 900 / 1500: loss 0.321887\n",
      "iteration 1000 / 1500: loss 0.455997\n",
      "iteration 1100 / 1500: loss 0.414923\n",
      "iteration 1200 / 1500: loss 0.404668\n",
      "iteration 1300 / 1500: loss 0.421432\n",
      "iteration 1400 / 1500: loss 0.386387\n",
      "iteration 0 / 1500: loss 0.714080\n",
      "iteration 100 / 1500: loss 0.522763\n",
      "iteration 200 / 1500: loss 0.498210\n",
      "iteration 300 / 1500: loss 0.480198\n",
      "iteration 400 / 1500: loss 0.487092\n",
      "iteration 500 / 1500: loss 0.460772\n",
      "iteration 600 / 1500: loss 0.478392\n",
      "iteration 700 / 1500: loss 0.404342\n",
      "iteration 800 / 1500: loss 0.426479\n",
      "iteration 900 / 1500: loss 0.436229\n",
      "iteration 1000 / 1500: loss 0.452220\n",
      "iteration 1100 / 1500: loss 0.392585\n",
      "iteration 1200 / 1500: loss 0.430915\n",
      "iteration 1300 / 1500: loss 0.409520\n",
      "iteration 1400 / 1500: loss 0.413970\n",
      "iteration 0 / 1500: loss 0.689645\n",
      "iteration 100 / 1500: loss 0.478630\n",
      "iteration 200 / 1500: loss 0.482152\n",
      "iteration 300 / 1500: loss 0.434622\n",
      "iteration 400 / 1500: loss 0.395137\n",
      "iteration 500 / 1500: loss 0.436640\n",
      "iteration 600 / 1500: loss 0.451950\n",
      "iteration 700 / 1500: loss 0.450593\n",
      "iteration 800 / 1500: loss 0.411029\n",
      "iteration 900 / 1500: loss 0.429315\n",
      "iteration 1000 / 1500: loss 0.430584\n",
      "iteration 1100 / 1500: loss 0.429378\n",
      "iteration 1200 / 1500: loss 0.451915\n",
      "iteration 1300 / 1500: loss 0.420478\n",
      "iteration 1400 / 1500: loss 0.389222\n",
      "iteration 0 / 1500: loss 0.597981\n",
      "iteration 100 / 1500: loss 0.000000\n",
      "iteration 200 / 1500: loss 0.000000\n",
      "iteration 300 / 1500: loss 0.000000\n",
      "iteration 400 / 1500: loss 24.813800\n",
      "iteration 500 / 1500: loss 0.000253\n",
      "iteration 600 / 1500: loss 0.000041\n",
      "iteration 700 / 1500: loss 41.284312\n",
      "iteration 800 / 1500: loss 0.000000\n",
      "iteration 900 / 1500: loss 0.000000\n",
      "iteration 1000 / 1500: loss 52.349998\n",
      "iteration 1100 / 1500: loss 0.000000\n",
      "iteration 1200 / 1500: loss 0.000000\n",
      "iteration 1300 / 1500: loss 0.000000\n",
      "iteration 1400 / 1500: loss 13.152268\n",
      "iteration 0 / 1500: loss 0.686366\n",
      "iteration 100 / 1500: loss 0.465489\n",
      "iteration 200 / 1500: loss 0.597914\n",
      "iteration 300 / 1500: loss 0.520923\n",
      "iteration 400 / 1500: loss 0.891702\n",
      "iteration 500 / 1500: loss 0.373477\n",
      "iteration 600 / 1500: loss 0.442239\n",
      "iteration 700 / 1500: loss 0.341313\n",
      "iteration 800 / 1500: loss 0.360226\n",
      "iteration 900 / 1500: loss 0.380369\n",
      "iteration 1000 / 1500: loss 0.344089\n",
      "iteration 1100 / 1500: loss 0.353238\n",
      "iteration 1200 / 1500: loss 0.402268\n",
      "iteration 1300 / 1500: loss 0.620668\n",
      "iteration 1400 / 1500: loss 0.358378\n",
      "iteration 0 / 1500: loss 0.722561\n",
      "iteration 100 / 1500: loss 0.407896\n",
      "iteration 200 / 1500: loss 0.477201\n",
      "iteration 300 / 1500: loss 0.482911\n",
      "iteration 400 / 1500: loss 0.474685\n",
      "iteration 500 / 1500: loss 0.389655\n",
      "iteration 600 / 1500: loss 0.447932\n",
      "iteration 700 / 1500: loss 0.366937\n",
      "iteration 800 / 1500: loss 0.521208\n",
      "iteration 900 / 1500: loss 0.417746\n",
      "iteration 1000 / 1500: loss 0.331356\n",
      "iteration 1100 / 1500: loss 0.375292\n",
      "iteration 1200 / 1500: loss 0.393117\n",
      "iteration 1300 / 1500: loss 0.363119\n",
      "iteration 1400 / 1500: loss 0.432623\n",
      "iteration 0 / 1500: loss 0.695482\n",
      "iteration 100 / 1500: loss 0.344773\n",
      "iteration 200 / 1500: loss 0.380623\n",
      "iteration 300 / 1500: loss 0.489966\n",
      "iteration 400 / 1500: loss 0.436838\n",
      "iteration 500 / 1500: loss 0.398722\n",
      "iteration 600 / 1500: loss 0.398022\n",
      "iteration 700 / 1500: loss 0.439427\n",
      "iteration 800 / 1500: loss 0.357401\n",
      "iteration 900 / 1500: loss 0.381290\n",
      "iteration 1000 / 1500: loss 0.568275\n",
      "iteration 1100 / 1500: loss 0.329402\n",
      "iteration 1200 / 1500: loss 0.384275\n",
      "iteration 1300 / 1500: loss 0.337895\n",
      "iteration 1400 / 1500: loss 0.357395\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 train accuracy: 0.794300 val accuracy: 0.796000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 train accuracy: 0.812800 val accuracy: 0.815000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 train accuracy: 0.815500 val accuracy: 0.823000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 train accuracy: 0.815200 val accuracy: 0.816000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 train accuracy: 0.705800 val accuracy: 0.703000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 train accuracy: 0.820900 val accuracy: 0.817000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 train accuracy: 0.836000 val accuracy: 0.822000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 train accuracy: 0.832600 val accuracy: 0.829000\n",
      "best validation accuracy achieved during cross-validation: 0.829000\n",
      "Binary logistic regression on raw pixels final test set accuracy: 0.809000\n"
     ]
    }
   ],
   "source": [
    "# You are encouraged to experiment with additional values\n",
    "learning_rates = [1e-7, 5e-6]\n",
    "batch_sizes = [1, 100, 200, 500]\n",
    "\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_logistic = None # The LogisticRegression object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "#                            START OF YOUR CODE                                #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# iterate over every possible combinations of learning rates and batch sizes\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        # learn a model using the training model\n",
    "        logistic = LogisticRegression(X_train, y_train)\n",
    "        logistic.train(X_train, y_train, learning_rate=learning_rate, \n",
    "                                        num_iters=1500, batch_size=batch_size, verbose=True)\n",
    "        \n",
    "        # calculate the accuracy of the validation set\n",
    "        val_accuracy = logistic.calc_accuracy(X_val, y_val)\n",
    "        \n",
    "        # save the accuracies in results as tuple of accuracy accordign to the training dataset and validation dataset\n",
    "        results[(learning_rate, batch_size)] = (logistic.calc_accuracy(X_train, y_train), val_accuracy)\n",
    "        \n",
    "        # save the best perceptron - the highest accuracy of the validation set\n",
    "        if val_accuracy > best_val:\n",
    "            \n",
    "            # update best_val and best_perceptron\n",
    "            best_val = val_accuracy\n",
    "            best_logistic = logistic\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, batch_size in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, batch_size)]\n",
    "    print ('lr %e batch_size %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, batch_size, train_accuracy, val_accuracy))\n",
    "    \n",
    "print ('best validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "test_accuracy = best_logistic.calc_accuracy(X_test, y_test)\n",
    "print ('Binary logistic regression on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdRdvKwR7MdF"
   },
   "source": [
    "# The End!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
